\chapter{Introduction}%
\label{chap:intro}

\section{Motivation}%
\label{sec:intro:motivation}

Computer technology is one of the most influential inventions in human history and a central driving force behind innovation in the \nth{20} and early \nth{21} centuries. It was indispensable for several scientific and technological breakthroughs like space exploration, gene sequencing, and the creation of the Internet to name only a few. The most valuable property, which made the computer successful, is its programmability. This distinguishes the computer from all other tools humans invented. From the beginning, it did not serve a specific purpose but could be used ubiquitously. This implicates that a computer cannot fulfill a meaningful purpose on its own; it needs a programming to do so.

In the early days of computer history when computers were slow and had only basic input and output systems, the programming was entered by a human manually. The programs back then were not interactive and did not depend on each other. So the operator could decide in which order the programs were run. As computing time was extremely precious, this order was based on a given schedule that was created based on different factors, \eg, importance, job submission order, or costs. When computers became faster, the manual program input was replaced by punched cards. The job scheduling was now given by order of the programs in the punched cards stack but did not differ much from the manual input.

With the introduction of personal computers, a new challenge was introduced. Now, the work consisted not only of jobs that had to be executed without additional input from the beginning to the end, but the user interacted with it. This led to the introduction of multitasking, where two or more jobs run concurrently on one machine. In the beginning, it was limited to cooperative multitasking, where a job or application voluntarily cedes processing time to another. This made it necessary to introduce a new facility to the system: the \emph{process scheduler}. It decides which program is served next as soon as another program releases the processor. With increasing computational power, the concept of cooperative multitasking evolved into preemptive multitasking, where a program no longer needs to release the processor voluntarily but can be forced to release it by the operating system. With this evolution, the process scheduler is not only responsible for deciding which program to run next, when consulted, but also which share of processing resources gets allocated to every executed program.

Today, the scheduler is an indispensable component of nearly every operating system and fundamentally determines the general behavior of the operating system itself and the whole system overall, \eg, it decides whether the system is more suited for embedded, desktop, server, or mainframe requirements. With the omnipresent use of computer technology, the diversity and complexity of scheduling algorithms also increased over time. The diversity, too, grew by the fact that single computer systems are not sufficient to solve more complicated problems or sustain service for a large user base.

Without exaggeration, it can be stated that the scheduler is a fundamental component in system software design to unfold the computational power of future systems. However, the design and implementation of scheduling policies is a complicated process. Most operating systems have grown over many years and do not use modern software design methods. An accelerating pace of changes in the hardware architecture and rising degree of concurrency make the task of developing future scheduling strategies even harder.

\section{Future Challenges}%
\label{sec:intro:challenges}

Operating system design has been facing more and more challenges in the recent years. They stem from the increasing pace and fundamental changes in innovation in information technology, especially computer architecture. This section gives an introduction to those challenges.

\subsection{Hardware Innovation}%
\label{sec:intro:challenges:innovation}

In computer technology, innovation cycles are becoming shorter and shorter, which can be attributed to the exponential growth in informatics. This can be traced back to \emph{Moore's} law~\cite{Moore-1965-Law} and is further elaborated by \textcite{Kurzweil-2004-AcceleratingReturns} in the \emph{Law of Accelerating Returns}. This was no issue for system software design as long as performance growth was achieved by increasing clock rates. It was not necessary to adapt the system software widely to make the additional power accessible to the user. However, this paradigm radically changed around the year 2003 when processor designs hit the power wall~\cite{Patterson-2011-ComputerArchitecture}. As the increase of clock rates flatlined (\cf{} \cref{fig:intro:arch2}), the performance improvements were still significant even though not as high as between the years 1986 and 2003 (\cf{} \cref{fig:intro:arch1}). Since 2003, performance improvements through increased clock rates were only marginal. Now, the main performance growth was achieved through other means. The first of those was moving from single-core to multi-core CPUs. At first, this did not pose an issue for the operating systems, as the multi-core model was already known from multiprocessor systems in high-performance computing environments. Early multi-core CPUs even had a similar architecture as multiprocessor systems.  However, multi-core systems evolved and became diverse, which made it more challenging for the operating system to manage them.


\begin{figure}\centering
	\begin{subfigure}[b]{\textwidth}\centering
		\includetikz{figures/chapter1-introduction/performance-growth}
		\caption[Growth in processor performance since the late 1970s.]{Growth in processor performance since the late 1970s~\cite[3]{Patterson-2011-ComputerArchitecture}.}%
		\label{fig:intro:arch1}
	\end{subfigure}\vspace{0.5cm}
	\begin{subfigure}[b]{\textwidth}\centering
		\includetikz{figures/chapter1-introduction/clock-rate-growth}
		\caption[Growth in clock rate of processors since the late 1970s.]{Growth in processor clock rates of since the late 1970s~\cite[24]{Patterson-2011-ComputerArchitecture}.}%
		\label{fig:intro:arch2}
	\end{subfigure}
	\caption[Comparison between processor performance and clock rates.]{Comparison between processor performance and clock rates since the late 1970s. The performance of the different systems is plotted in relation to the VAX-11/780 based on the SPEC benchmark~\cite{SPEC}. The machines were benchmarked with the current SPEC versions of their time. The performance of newer machines is estimated through a scaling factor between the different SPEC versions.}%
	\label{fig:intro:arch}
\end{figure}

One example of that issue was the introduction of the Bulldozer microarchitecture by AMD in 2011. Bulldozer CPUs were unique compared to other CPUs back then, because, unlike in a real multi-core CPU, two Bulldozer cores shared one floating-point unit. Because the Bulldozer based CPUs were designated as desktop CPUs, one of the main operating systems running those CPUs was Microsoft Windows. However, because of the unique architecture, using Windows together with a Bulldozer based CPU resulted in performance issues with multi-threaded applications~\cite{Angelini-2011-Bulldozer}. The issue could be traced back to the Windows process scheduler that treated every processing unit as an independent physical core, which they were not because of the shared floating-point unit. Even though the product was already publicly available in October~2011 and undoubtedly even earlier to Microsoft, they released the first scheduler fix~\cite{Microsoft-2011-PatchBulldozer-A} only in December~2011. Even worse, this patch did not fix the problem and had to be withdrawn. A functional patch was only released in January~2012~\cite{Microsoft-2012-PatchBulldozer-B, Microsoft-2012-PatchBulldozer-C}. This example is just one brief episode giving an idea of the challenges operating systems in general and the process scheduler, in particular, will face in the future due to changing architectures. However, more significant changes in hardware architecture can be expected in the future. Based on \emph{Amdahl's} law~\cite{Amdahl-1967-Law} and its extension for multi-core systems~\cite{Hill-2008-AmdahlMC}, the performance improvement through additional cores cannot be maintained indefinitely. Therefore, new fundamentally different architectures have to be employed, if performance improvements are still to be achieved. The Intel Tera-Scale research program~\cite{Intel-2006-TerraScale} for example gave first insights how such architectures could look like. Since then, many new system architectures emerged.

\subsection{Heterogeneous Systems}%
\label{sec:intro:challenges:hetero}

Another challenge in scheduler design are heterogeneous systems. In such a system, the cores or \acp{PE} of the system have different properties. The degree of heterogeneity can range from very low like, \eg, minor differences in energy consumption to very high like, \eg, differences in the programming model or even special purpose \acp{PE}. Depending on the degree of heterogeneity, issues of different severities can arise.

The following example illustrates the struggle in scheduler design again, this time originating from the emergence of heterogeneous systems. The fast rise of mobile computing in the recent years lead to new requirements in CPU design~\cite{McGregor-2009-EvolutionMobile}, which is especially the need to conserve energy. First, it was countered with microarchitectures optimized for high efficiency, \eg{}, maximizing the number of \ac{FLOPS} per Watt. The most prominent example of this effort is the ARM architecture developed by \emph{ARM Holding}. However, with the rising computational demand of mobile applications, a specialized microarchitecture was not any longer sufficient to keep the balance between high efficiency and peak performance. For this reason, ARM introduced the big.LITTLE architecture, which was announced in October~\citeyear{ARM-2011-BigLittle}~\cite{ARM-2011-BigLittle}. The big.LITTLE concept combines highly energy efficient low-performance cores with energy demanding high-performance cores in one multi-core CPU. It is an example of a heterogeneous multi-core system even though the degree of heterogeneity is very low as the cores have the same instruction set and mainly differ in performance. The performance difference poses a challenge for the scheduler as a past common assumption in multi-core scheduler design was that cores are similar and therefore interchangeable. This disruption led to the fact that a scheduler for the Linux kernel -- which is the main system software running this sort of CPUs -- that can handle all cores at the same time was only available in July~\citeyear{Grey-2013-GTS}~\cite{Grey-2013-GTS}. The changes necessary to the Linux scheduler were so severe that it remained until~2015 only available for the kernel that was stable in July~2013.

Again, this is only one brief episode of challenges in the scheduling of heterogeneous systems. For example, recent research has shown that even small differences in hardware architecture have to be considered by the scheduler to reach optimal performance~\cite{Busse-2013-Interdependencies}. However, other more disruptive challenges regarding heterogeneity are present today or will arise in the future. For example, certain computational problems can benefit from processing accelerators that yield a better performance both in absolute processing time and energy consumption per solved problem~\cite{Huang-2009-GPU, Thomas-2009-GPUFPGA, Hamada-2009-GPUFPGA, McIntosh-Smith-2012-CPUGPU, Betkaoui-2010-FPGAGPU}. \acp{GPU} can be considered as such a processing accelerator. With the availability of the \ac{CUDA}~\cite{CUDA} in 2007 and \ac{OpenCL}~\cite{OpenCL} in 2009, \ac{GPGPU}~\cite{Thompson-2002-GPGPU} that uses \acp{GPU} as processing accelerators became widely available. \ac{GPGPU} has a completely different computing and programming model compared to general purpose \acp{PE}~\cite{Stone-2010-OpenCLModel}. However, from the resource perspective of the operating system, those devices are not significantly different from general purpose CPUs: They consist of \acp{PE} that can be used by different tasks in a time division manner. Therefore, processing accelerators should be managed and assigned by a process scheduler. Currently, the management is realized through specialized libraries often in the user space and has only limited scheduling capabilities. However, the scheduling and sophisticated management of processing units for \ac{GPGPU} are ongoing research, \eg, \textcite{Bautin-2008-GPUSCHED} or \citeauthor{Kato-2011-GPUSched}~\cite{Kato-2011-GPUSched,Kato-2012-GPUSched}.

Besides \acp{GPU}, several other kinds of accelerators exist with different programming models. On the one side of the spectrum, there is, for example, the Intel \ac{MIC} architecture~\cite{Intel-2011-mic, Duran-2012-mic}, which is marketed under the name Intel Xeon Phi. Even though the first generation of the \ac{MIC} architecture was released entirely and the second one partially as dedicated processing accelerator, it has a programming model that is very similar to the model of multi-core CPUs. On the other side of the spectrum, there are \acp{ASIC} that have little to none programmability and are heavily tailored to special purposes like \eg{} data compression~\cite{Indra-2007}, mining of crypto currencies\footnote{The money supply of a crypto currency is controlled by a cryptographic algorithm with a high computational complexity rather than a central bank~\cite{Greenberg-2011-bitcoin}.}~\cite{Antminer-2014, Asicminer-2014}, machine learning~\cite{Jouppi-2016-TPU}, or image processing~\cite{Moloney-2014-Myriad}.

\subsection{Reconfigurable Computing}%
\label{sec:intro:anycore}

With the challenges pointed out in the previous subsections, the scheduling problem became more complex but remained mostly the same: several tasks with different requirements had to be assigned over time to a fixed number of \acp{PE} with specific capabilities. The hardware architecture is static and does not change during the runtime of the system. With \ac{FPGA} technology\footnote{For details on \ac{FPGA} technology itself refer to, \eg, \textcite{Compton-2002-FGPAGeneral}.}, this might change drastically in the near future. Today, \acp{FPGA} are commonly used as processing accelerators as mentioned in \cref{sec:intro:challenges:hetero} or as co-processors to achieve hard real-time through jitter and latency reduction. In those scenarios, \acp{FPGA} are statically configured and do not change their functionality during runtime. Therefore, in those scenarios, they are not different from specialized \acp{PE}. However, this limitation is not necessary, because they can be reconfigured with almost no limitation during runtime. Considering this aspect, the scheduling problem becomes entirely different from many points of view.

A logic block or even a \ac{LUT} might be considered as the smallest \ac{PE} of a \ac{FPGA}. A \ac{FPGA} has hundreds of thousands of those, which is an order of \num{100} or \num{1000} more than \acp{PE} in a many-core chip. This turns the scheduling problem towards a continuous problem rather than a discrete one. First because of the sheer number, and second because single \acp{LUT}, contrary to other \acp{PE}, cannot fulfill computations completely on their own. Furthermore, many side conditions have to be considered. In practice, as a \ac{LUT} virtually cannot process data on its own, several adjacent \acp{LUT} have to be combined. Moreover, certain timing conditions have to be met also influencing the number of \acp{LUT} needed and have to be taken into account during the scheduling decision. In addition to simple logic blocks, modern \acp{FPGA} incorporate specialized processing blocks like \acp{DSP} or I/O blocks that have to be considered as well when assigning the resources of a \ac{FPGA}.

Today, \acp{FPGA} can still be considered a niche product in servers and especially workstations and desktops. This might change soon as Intel, by far one of the biggest suppliers for data center processors, will integrate \ac{FPGA} technology in its server processors~\cite{Bryant-2014-XeonFPGA}. Also, with the Zynq series~\cite{Xilinx-2016-Zynq}, Xilinx combines established and widely used ARM cores tightly with their \ac{FPGA} technology. This will make \acp{FPGA} more widely available and therefore another processing resource for the operating system to manage. The benefits of such systems are discussed, \eg, by \textcite{Chung-2010-Singl-ChipHetero}.

The management of \acp{FPGA} in the operating system was already suggested by \textcite{Brebner-1996-FPGAOS} in 1996. Since then, several projects emerged with the goal of making \acp{FPGA} readily available to the user. Such projects are BORTH~\cite{So-2007-BORTH} that supports hardware tasks abstracting the hardware configuration as Unix process or ReconOS~\cite{Lubbers-2009-ReconOS} that enables a programming model for a \ac{FPGA} similar to \acp{Pthread}.

\subsection{Dark Silicon}

The notion of \emph{dark silicon} was introduced by \textcite{Esmaeilzadeh-2011-DarkSilicon}. In their 2011 paper, they project that multicore microchips produced with a \SI{8}{\nano\meter} process required more than \SI{50}{\percent} of the chips' transistors to be powered off at all time. The powered off part of a chip is denoted as dark silicon. The reason for that restraint is the same as the introduction of multi-core and heterogeneous systems, the breakdown of \emph{Dennard scaling}~\cite{Dennard-1974-Design} beginning in the mid of the first decade of the \nth{21}~century. Dennard scaling states that the total chip power for a given die size stays the same in each process generation. However, this statement holds no longer as transistor energy efficiency only improves by a factor of \num{1.4} every two years while transistor density continues to improve, following \emph{Moors} law, by a factor of two in the same time frame~\cite{Taylor-2013-DarkSiliconLandscape}. A consequence of this development is the possibility that in the future energy will be by far the biggest constraint regarding chip design in contrast to the die area and transistor count in the past.

The previous sections of this dissertation already discussed initial approaches to reduce the impact of the breakdown of Dennard scaling. However, those approaches will most likely not overcome the necessity that certain parts of a chip have to be dark and even further specialized in the future~\cite[\cf][]{Taylor-2012-DarkSilicon}. This development has a significant impact on the operating systems scheduler. Even though today certain power constraints have to be considered, with dark silicon the whole problem becomes much more complicated. Whereas today the power management can be seen as a micromanagement problem as only the overall system energy consumption is important, in the era of dark silicon the scheduler has to do micromanagement to ensure that the microchips of a system are not overheating and that the system can still unfold its full processing power potential.

\subsection{Virtualization}

Virtualization is another answer to the increasing computational power of modern hardware. As modern servers are often not fully utilized by a single service, for economic reasons it makes sense to run several services on one machine. However, contrary to multi-tasking, different services need different runtime environments. Furthermore, especially in the context of cloud computing, various services from different clients have to be fully isolated from each other. Another benefit of virtualization is that running services can be seamlessly migrated to a new host with minimal interruption.

Regarding the process scheduling, virtualization introduces another challenge, as the virtual machine brings its own scheduler that is completely isolated from the host scheduler\footnote{An exception is operating-system-level virtualization that uses the host scheduler.}, interference between these two can be expected. Even when the virtual machines' scheduler tries to achieve the same optimization goal as the host, taking actions to achieve this might interfere with the steps taken by the host's scheduler. This is because, today, the host and guest scheduler are completely separated and do not share information.

With increasing degree of heterogeneity and new computational approaches as described in the previous sections, the question arises how the guest of a virtual host can benefit from those improvements. It is plausible to assume that in such a situation it becomes even more viable to provide additional information both to the guest and host scheduler to reach an optimal scheduling decision.

\subsection{Complexity}

The growing complexity of operating systems in general and schedulers in particular paired with low-level programming languages with small expressiveness resemble another challenge in scheduler development. The scheduler subsystem \eg{} of the Linux Kernel v4.4 alone consists of approximately 16,500 lines of low-level C code and is tightly coupled to the rest of the kernel that has about 150,000 lines of code excluding device drivers. Besides the technological changes described in the previous subsections, the increasing complexity of scheduler designs can be found due to economic and convenience reasons.

In the past, operating systems were tailored to a specific application domain like embedded, desktop, or server systems. Today, one operating system is used in multiple domains. Take for example Windows. At the end of the 1990s, there were three operating system lines each with a distinct kernel: Windows~9x for desktop environments, Windows~NT for workstations and servers, and Windows~CE for embedded and later also mobile devices. With the introduction of Windows~10, Microsoft started using one operating system kernel for all of those domains. The same trend can be observed for the Linux kernel that is also used for many different domains ranging from high performance and supercomputing down to embedded devices. This trend makes it necessary to have a kernel that can fulfill all the specific needs of the different domains, therefore, increasing code complexity.

\subsection{Monopolization}%
\label{sec:intro:monopol}

\begin{table}[t!] \centering
	\begin{threeparttable}[b]
		\caption[Number of commiters per year for selected open source operating systems.]{Number of committers per year for selected open source operating systems between 2010 and 2015. The numbers were acquired from the respective source code repositories.}%
		\label{table:devs}
		\begin{tabular}{lrrrrrr} \toprule
			\multirow{2}{*}{\raisebox{-8.5pt}{\breakC{Operating System \\ or Kernel}}}    & \multicolumn{6}{c}{Year} \\ \cmidrule(lr){2-7}
			              & \textbf{2010}         & \textbf{2011} & \textbf{2012} & \textbf{2013} & \textbf{2014} & \textbf{2015} \\\midrule
			Linux         & 2757                  & 2852          & 2934          & 3237          & 3548          & 3656          \\
			FreeBSD       & 195                   & 193           & 205           & 205           & 201           & 183           \\
			NetBSD        & 138                   & 128           & 126           & 113           & 114           & 103           \\
			%            OpenBSD         & 107    &         &         &         &         &         \\ 
			DragonFly BSD & 4                     & 22            & 28            & 31            & 30            & 25            \\
			Haiku         & 43                    & 51            & 78            & 61            & 66            & 56            \\
			Barrelfish    & --\tnote{\textdagger} & 14            & 19            & 18            & 13            & 12            \\
			Minix         & 11                    & 15            & 19            & 28            & 26            & 15            \\
			GNU Hurd      & 14                    & 14            & 15            & 8             & 12            & 10            \\
			GNU Mach      & 4                     & 10            & 11            & 9             & 7             & 9             \\ \bottomrule
		\end{tabular}
		\begin{tablenotes}
			\item[\textdagger] Source code history not available prior to 2011.
		\end{tablenotes}
	\end{threeparttable}
\end{table}

The last major challenge in scheduler development was indirectly already shown in the example in \cref{sec:intro:challenges:hetero} with the big.LITTLE architecture. So far, there is only one notable effort to enable an adapted scheduling to this platform for the Linux kernel but no other operating system. The reason can be easily concluded when examining the number of active committers to several open source operating systems as depicted in \cref{table:devs}. It can be observed that Linux has by far the most contributors and therefore is the most likely platform when adapting new technologies. It even wins more developers year by year than other platforms have developers at all. This would not be an issue if implementations from one operating system could easily be used in another operating system. However, most implementations are extremely specific to the operating system they are developed for. Therefore, porting a feature from one operating system to another mostly means a complete rewrite or at least a significant effort.

\section{About this Dissertation}

The thesis that this dissertation supports is:\vspace{3mm}
\begin{center}
	\begin{minipage}{.85\textwidth}\itshape{}
		To harvest the capabilities of future computer systems to their fullest extent, a novel dynamic approach to scheduler architecture is needed that is capable of being integrated into legacy operating systems.
	\end{minipage}
\end{center}\vspace{3mm}
The previous sections have shown that operating system development in general and process scheduler development in particular, are facing many challenges while, at the same time, they have to be highly innovative to enable operating systems to fulfill their purpose as an intermediary between the hardware and the user applications. This dissertation means to overcome those obstacles for the process scheduler and puts the developer in a position where he or she can apply their knowledge to the fullest extent.

To achieve that goal, the development process has to become more transparent. Today's operating system schedulers of well established operating systems are scattered all over the operating system code with unmentioned interdependencies, written in low-level programming languages, and have poorly documented interfaces. All this has to change to enable a fast and prospering innovation process. Furthermore, the implementations have to be testable in a convenient way, allowing a fast prototyping and straightforward way to try new ideas. The latter one is inevitable for the future because the increasing pace of architecture changes will require new possibly bold approaches to process scheduling where a development and real life testing process lasting several months simply cannot be afforded.

Based on the increasing complexity of system architectures, the scheduler developer cannot be an expert on both architectural properties and specifics of several different operating systems. That means that the development process should be as independent as possible from the runtime system; yet, the developer should be able to test his or her approach in well established operating systems. To test the implementation easily not only in a simulated environment but also on the desired target systems will give an estimate whether it is worth optimizing the implementation for the target system.

Finally, to further speed up the development process, the reuse of existing and upcoming implementations has to be increased and promoted. With constantly changing architectures, a developer has to rely on previously found solutions to specific problems and should not be bothered with reimplementing them. Instead, he or she has to be enabled to reuse the existing solution in the new scheduling approach in an easy way.

With these properties fulfilled, it will be possible to design holistic schedulers that are entirely optimized for the specific system. It will no longer be necessary to conduct scheduling tasks in the user space, especially regarding processing accelerators. The operating system will, again, be in charge of the complete resource management of the machine.

This dissertation proposes a Component Based Scheduling (\cobas) framework for fast prototyping of new scheduler algorithms. The framework is not limited to a specific architecture and does not use a greenfield approach. Instead, it fits into the existing runtime environments. It enables the scheduler developer to quickly try new ideas both in artificial as well as real life environments overcoming the limitations mentioned above.

\section{Contributions}%
\label{sec:intro:contributions}

The contributions of this dissertation fall into four areas:

\textbf{Heterogeneous Many-Core Support:} The proposed scheduler framework provides an infrastructure to build schedulers for heterogeneous many-core architectures. By design, it can be scaled to a significant number of cores and can handle different architectural characteristics.

\textbf{Adaptability:} Changes to the system architecture during runtime might become common in the future. \cobas{} can support this by changing the scheduler during runtime. Both the structure of the scheduler and the scheduling policies can be modified without rebooting the system. Distinct resource managers for specialized \acp{PE} are no longer necessary.

\textbf{Composition:} Scheduling policies can be composed of independent components. This dissertation discusses what components are composable based on their functionality and gives a classification of the components used for the \cobas{} framework.

\textbf{Runtime System Independence:} Through a case study, this dissertation shows that the proposed framework is mostly independent of the runtime system. Existing components can be reused beyond the boundaries of a specific runtime system.

\section{Outline of the Dissertation}

The remainder of the dissertation is structured as follows: The next chapter delves further into the functional challenges that were initially laid out by this chapter. \Cref{chap:requirements} continues to deduce requirements based on the discussion of the first two chapters of this dissertation that have to be addressed to tackle the outlined challenges. Following, \cref{chap:related_work} presents work related to this dissertation. It, on the one hand, presents previous research that tried to tackle some of the challenges discussed and, on the other hand, presents technology relevant to this dissertation. \Cref{chap:arch} introduces the \cobas{} framework that tackles the challenges discussed in the previous chapters. This includes, in particular, those problems not addressed by previous research. The subsequent \cref{chap:prop} gives an initial theoretical evaluation of the \cobas{} framework before \cref{chap:proto} presents a prototypical implementation of the \cobas{} framework in detail. The following \cref{chap:study} presents an extensive practical evaluation of the \cobas{} architecture based on the prototype. \Cref{chap:conclusion} concludes this dissertation. It revisits the contributions claimed in \cref{sec:intro:contributions}, discusses the strengths and weaknesses of this work, and gives directions for future research. In addition, \cref{appendix:cobas} gives further technical details of the \cobas{} prototype implementation and \cref{appendix:data} records detailed data generated from the experiments in \cref{chap:study}.

The bibliography consists of two parts. The first part contains literature that is referenced throughout this dissertation. The second part contains references to software or software projects. To distinguish between references to these two parts, references to software are prefixed with an \emph{S}.
